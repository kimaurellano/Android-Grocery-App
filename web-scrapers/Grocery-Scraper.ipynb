{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################################\n",
    "######################################### LIBRARIES #########################################\n",
    "#############################################################################################\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver import ActionChains\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#import pymysql\n",
    "import sqlite3\n",
    "\n",
    "from datetime import datetime\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql\n",
    "%sql sqlite:///grocery.sqlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "---DROP TABLE smmarkets;\n",
    "\n",
    "CREATE TABLE smmarkets (\n",
    "    productID       TEXT NOT NULL,\n",
    "    webpage         TEXT NOT NULL,\n",
    "    productLink     TEXT NOT NULL,\n",
    "    productCategory TEXT NOT NULL,\n",
    "    productName     TEXT NOT NULL,\n",
    "    productPrice    TEXT NOT NULL\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT * FROM smmarkets;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################################\n",
    "########################################## SET UP ###########################################\n",
    "#############################################################################################\n",
    "\n",
    "\n",
    "### Path/Location of Chromedriver\n",
    "#dirpath = os.getcwd()\n",
    "filepath = 'C:/Users/Mystycalpha/chromedriver'\n",
    "\n",
    "### File name and path/location where the dataframe will be exported to CSV\n",
    "filename = \"smmarkets-links.csv\"\n",
    "savepath = \"C:/Users/Mystycalpha/Desktop/Grocery App\" + filename\n",
    "\n",
    "### List of Links\n",
    "wpg_list = []\n",
    "with open(\"smmarket-links-list-Copy.txt\", 'r') as f:\n",
    "        wpg_list = [l.strip(\"\\n\") for l in f]\n",
    "\n",
    "#print(wpg_list)\n",
    "\n",
    "### Silence Chrome\n",
    "chrome_options = Options()  \n",
    "chrome_options.add_argument(\"--headless\")  \n",
    "\n",
    "### SQL Database\n",
    "conn = sqlite3.connect(\"grocery.sqlite\") #pymysql.connect(host='127.0.0.1',user='root', passwd = '', db = 'mysql', charset = 'utf8')\n",
    "cur = conn.cursor()\n",
    "#cur.execute(\"USE groceryDB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################\n",
    "##### Export data to DB #####\n",
    "\n",
    "def storeDB(new_entry):\n",
    "        #dateScraped = datetime.now(tz=None)\n",
    "        val = (new_entry['webpage'], new_entry['productID'], new_entry['productLink'],\n",
    "               new_entry['productCategory'], new_entry['productName'], new_entry['productPrice'])\n",
    "        query = '''\n",
    "        INSERT INTO smmarkets (webpage, productID, productLink, productCategory, productName, productPrice)\n",
    "        VALUES (?, ?, ?, ?, ?, ?);\n",
    "        '''                \n",
    "        #print(query)\n",
    "        cur.execute(query, val)\n",
    "        conn.commit()\n",
    "        #cur.connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "##### Creating the Dataframe #####\n",
    "\n",
    "### Make column list of categories / features for the creation of dataframe\n",
    "column_list = ['webpage', 'id', 'link', 'category', 'name', 'price']\n",
    "\n",
    "### Create empty dataframe\n",
    "df = pd.DataFrame(columns=column_list)\n",
    "\n",
    "\n",
    "####################################\n",
    "##### Chromedriver and Browser #####\n",
    "\n",
    "print('Path to Driver: ', filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "##### Run function for scraping #####\n",
    "\n",
    "\n",
    "for wpg in wpg_list:\n",
    "        browser = webdriver.Chrome(executable_path = filepath, options = chrome_options)\n",
    "        print(wpg)\n",
    "        browser.get(wpg)\n",
    "        \n",
    "        sleep(1)\n",
    "\n",
    "        print(\"\\n################################################################################\")\n",
    "\n",
    "        try:\n",
    "            loaded = WebDriverWait(browser, 10).until(EC.presence_of_element_located((By.XPATH, '/html/body/div[7]/div[2]/div/div[2]')))\n",
    "\n",
    "            category = loaded.find_element_by_xpath('/html/body/div[7]/div[2]/div/div[2]/div[2]/div[1]/div/h1').get_attribute('innerHTML')\n",
    "            if \"amp;\" in str(category):\n",
    "                category = category.replace(\"amp;\", \"\")\n",
    "            print('Category:', category)\n",
    "            \n",
    "\n",
    "            sleep(1)\n",
    "            \n",
    "            try:\n",
    "                page_text = loaded.find_element_by_xpath('//*[@id=\"amscroll-navbar\"]/span').get_attribute('innerHTML')\n",
    "                pages = int(str(page_text).strip('\"').split(' ')[-1])\n",
    "\n",
    "            except Exception as e:\n",
    "                print(\"Error occured for pages:\", e)\n",
    "                with open(\"smmarket-scrape-errors.txt\", 'a+') as f:\n",
    "                    f.write('%s \\t Error occured for pages: \\t %s\\n' % (wpg, e))\n",
    "                pages = 1\n",
    "\n",
    "            print(\"Number of pages:\", pages)\n",
    "            \n",
    "            with open(\"smmarket-scrape-errors.txt\", 'a+') as f:\n",
    "                f.write('%s \\t Number of pages: \\t %s\\n' % (wpg, pages))\n",
    "            \n",
    "            browser.quit()\n",
    "\n",
    "            for p in range(1, pages+1):\n",
    "                wpg_pg = wpg + '?p=' + str(p)\n",
    "                browser = webdriver.Chrome(executable_path = filepath, options = chrome_options)\n",
    "                print(wpg_pg)\n",
    "                browser.get(wpg_pg)\n",
    "                \n",
    "                sleep(1)\n",
    "\n",
    "                products_grid = WebDriverWait(browser, 10).until(EC.presence_of_element_located((By.XPATH, '/html/body/div[7]/div[2]/div/div[2]/div[2]/div[2]/div[4]/ol')))\n",
    "                products = products_grid.find_elements_by_class_name('product-item')\n",
    "                \n",
    "                sleep(1)\n",
    "\n",
    "                for product in products:\n",
    "                    ### Get ID\n",
    "                    productID = \"smmarkets-\" + str(product.find_element_by_class_name('price-box').get_attribute('data-product-id'))\n",
    "\n",
    "                    ### Get Price\n",
    "                    price = product.find_element_by_class_name('price-wrapper').get_attribute('data-price-amount')\n",
    "\n",
    "                    ### Get Name\n",
    "                    link = product.find_element_by_class_name('product-item-link').get_attribute('href')\n",
    "\n",
    "                    ### Get Link\n",
    "                    name = product.find_element_by_class_name('product-item-link').get_attribute('innerHTML').strip()\n",
    "\n",
    "                    ### Save into new_entry that will be appended to the dataframe\n",
    "                    new_entry = {'webpage': wpg_pg.strip(), 'productID': productID, 'productLink': link, \n",
    "                                 'productCategory': category, 'productName': name, 'productPrice': price}\n",
    "\n",
    "                    #df = df.append(new_entry, ignore_index=True)\n",
    "                    storeDB(new_entry)\n",
    "\n",
    "                    ### Print all data gathered\n",
    "                    print(\"------------------------------------------------------------------------\")\n",
    "                    for label in new_entry:\n",
    "                        print(label.upper(), \":\", new_entry[label])\n",
    "                    print(\"------------------------------------------------------------------------\")\n",
    "                    \n",
    "                browser.quit()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"Error occured:\", e)\n",
    "            \n",
    "            with open(\"smmarket-scrape-errors.txt\", 'a+') as f:\n",
    "                f.write('%s \\t %s \\t %s\\n' % (wpg, wpg_pg, e))\n",
    "            \n",
    "            browser.quit()\n",
    "\n",
    "        finally:\n",
    "            browser.quit()\n",
    "\n",
    "\n",
    "\n",
    "#print(\"df shape:\", df.shape)\n",
    "#print(\"Finished\", wpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT COUNT(1) FROM smmarkets;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT productCategory, COUNT(1) AS count\n",
    "FROM smmarkets\n",
    "GROUP BY productCategory;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT webpage, COUNT(1) AS count\n",
    "FROM smmarkets\n",
    "GROUP BY webpage\n",
    "ORDER BY webpage;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "##### Run function for scraping #####\n",
    "\n",
    "wpg_list = [\n",
    "    [\"https://shop.smmarkets.ph/index.php/snacks.html\", 34, 70]\n",
    "]\n",
    "\n",
    "for w in wpg_list:\n",
    "        wpg = w[0]\n",
    "        start = w[1]\n",
    "        pages = w[2]\n",
    "        \n",
    "        browser = webdriver.Chrome(executable_path = filepath, options = chrome_options)\n",
    "        print(wpg)\n",
    "        browser.get(wpg)\n",
    "        \n",
    "        sleep(1)\n",
    "\n",
    "        print(\"\\n################################################################################\")\n",
    "\n",
    "        try:\n",
    "            loaded = WebDriverWait(browser, 10).until(EC.presence_of_element_located((By.XPATH, '/html/body/div[7]/div[2]/div/div[2]')))\n",
    "\n",
    "            category = loaded.find_element_by_xpath('/html/body/div[7]/div[2]/div/div[2]/div[2]/div[1]/div/h1').get_attribute('innerHTML')\n",
    "            if \"amp;\" in str(category):\n",
    "                category = category.replace(\"amp;\", \"\")\n",
    "            print('Category:', category)\n",
    "            \n",
    "            sleep(1)\n",
    "\n",
    "            print(\"Number of pages:\", pages)\n",
    "            \n",
    "            #with open(\"smmarket-scrape-errors.txt\", 'a+') as f:\n",
    "            #    f.write('%s \\t Number of pages: \\t %s\\n' % (wpg, pages))\n",
    "            \n",
    "            browser.quit()\n",
    "\n",
    "            for p in range(start, pages+1):\n",
    "                wpg_pg = wpg + '?p=' + str(p)\n",
    "                browser = webdriver.Chrome(executable_path = filepath, options = chrome_options)\n",
    "                print(wpg_pg)\n",
    "                browser.get(wpg_pg)\n",
    "                \n",
    "                sleep(1)\n",
    "\n",
    "                products_grid = WebDriverWait(browser, 10).until(EC.presence_of_element_located((By.XPATH, '/html/body/div[7]/div[2]/div/div[2]/div[2]/div[2]/div[4]/ol')))\n",
    "                products = products_grid.find_elements_by_class_name('product-item')\n",
    "                \n",
    "                sleep(1)\n",
    "\n",
    "                for product in products:\n",
    "                    ### Get ID\n",
    "                    productID = \"smmarkets-\" + str(product.find_element_by_class_name('price-box').get_attribute('data-product-id'))\n",
    "\n",
    "                    ### Get Price\n",
    "                    price = product.find_element_by_class_name('price-wrapper').get_attribute('data-price-amount')\n",
    "\n",
    "                    ### Get Name\n",
    "                    link = product.find_element_by_class_name('product-item-link').get_attribute('href')\n",
    "\n",
    "                    ### Get Link\n",
    "                    name = product.find_element_by_class_name('product-item-link').get_attribute('innerHTML').strip()\n",
    "\n",
    "                    ### Save into new_entry that will be appended to the dataframe\n",
    "                    new_entry = {'webpage': wpg_pg.strip(), 'productID': productID, 'productLink': link, \n",
    "                                 'productCategory': category, 'productName': name, 'productPrice': price}\n",
    "\n",
    "                    #df = df.append(new_entry, ignore_index=True)\n",
    "                    storeDB(new_entry)\n",
    "\n",
    "                    ### Print all data gathered\n",
    "                    print(\"------------------------------------------------------------------------\")\n",
    "                    for label in new_entry:\n",
    "                        print(label.upper(), \":\", new_entry[label])\n",
    "                    print(\"------------------------------------------------------------------------\")\n",
    "                    \n",
    "                browser.quit()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"Error occured:\", e)\n",
    "            \n",
    "            with open(\"smmarket-scrape-errors.txt\", 'a+') as f:\n",
    "                f.write('%s \\t %s \\t %s\\n' % (wpg, wpg_pg, e))\n",
    "            \n",
    "            browser.quit()\n",
    "\n",
    "        finally:\n",
    "            browser.quit()\n",
    "\n",
    "\n",
    "\n",
    "#print(\"df shape:\", df.shape)\n",
    "#print(\"Finished\", wpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT *\n",
    "FROM smmarkets\n",
    "WHERE productName LIKE \"%LIGO%\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql(\"SELECT * FROM smmarkets\", conn)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv = df.to_excel(\"smmarkets-links.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
